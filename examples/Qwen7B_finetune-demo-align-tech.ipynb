{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e7bef94-e459-4140-b533-cd6c188722b0",
   "metadata": {},
   "source": [
    "# 少量样本 QLoRA Finetune Qwen-7B/14B DEMO for Align Tech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a2b543-19b9-4312-b6b8-2eda7acc744e",
   "metadata": {},
   "source": [
    "## 运行环境确认"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a94d818-4b67-456e-9e68-3a66ac091d23",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36a77632-b0d7-48f4-8caf-aa03524cac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db0e1a3f-78f4-4294-8661-89d1f7db3474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.34.0\n"
     ]
    }
   ],
   "source": [
    "import transformers \n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bc7b26c-2cc6-4add-bb63-0ceecc2dd13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5.0\n"
     ]
    }
   ],
   "source": [
    "import peft \n",
    "print(peft.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f28e80c-b47a-4973-a1ec-d761ac412e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.0\n"
     ]
    }
   ],
   "source": [
    "import accelerate \n",
    "print(accelerate.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bd64c16-82c4-4c1d-9f74-5b734fe6b6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.4\n"
     ]
    }
   ],
   "source": [
    "import torchkeras\n",
    "print(torchkeras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "758611aa-70ab-4ce4-b512-8991315cdf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: bitsandbytes\n",
      "Version: 0.41.1\n",
      "Summary: k-bit optimizers and matrix multiplication routines.\n",
      "Home-page: https://github.com/TimDettmers/bitsandbytes\n",
      "Author: Tim Dettmers\n",
      "Author-email: dettmers@cs.washington.edu\n",
      "License: MIT\n",
      "Location: /home/ecs-assist-user/micromamba/envs/qwen/lib/python3.10/site-packages\n",
      "Requires: \n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show bitsandbytes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eb2757-a214-4626-9127-d238520bba82",
   "metadata": {},
   "source": [
    "## 下载目标模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d0f6f1a-0d35-4c1c-8544-fa0b4df112b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-19 14:41:28,033 - modelscope - INFO - PyTorch version 2.1.0 Found.\n",
      "2023-10-19 14:41:28,037 - modelscope - INFO - Loading ast index from /home/ecs-assist-user/.cache/modelscope/ast_indexer\n",
      "2023-10-19 14:41:28,210 - modelscope - INFO - Loading done! Current index file version is 1.9.2, with md5 fd57df25cf18fc0a972c98cfdffc3f42 and a total number of 941 components indexed\n"
     ]
    }
   ],
   "source": [
    "from modelscope import AutoModelForCausalLM, AutoTokenizer, snapshot_download\n",
    "target_model=\"qwen/Qwen-7B-Chat\"\n",
    "#target_model=\"qwen/Qwen-14B-Chat\"\n",
    "llm_weight_workspace='/mnt/llm-data/'\n",
    "model_name_or_path=llm_weight_workspace+target_model\n",
    "llm_finetune_checkpoint_workspace=llm_weight_workspace+'checkpoints/'+target_model\n",
    "llm_finetune_savepath=llm_weight_workspace+'finetuned/'+target_model\n",
    "#model_dir = snapshot_download(target_model, revision='v1.0.4',cache_dir=llm_weight_workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae3a0b3-bf03-46bd-bace-330665645f9a",
   "metadata": {},
   "source": [
    "## 〇，预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c0f2e17-7ed1-42e8-81f8-63a7bbeab31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM,AutoConfig, AutoModel, BitsAndBytesConfig\n",
    "from transformers.generation.utils import GenerationConfig\n",
    "import torch.nn as nn\n",
    "from torchkeras.chat import ChatLLM \n",
    "\n",
    "class ModelLoader(object):  # 创建Circle类\n",
    "   def __init__(self, model_name_or_path):  # 约定成俗这里应该使用r，它与self.r中的r同名\n",
    "       self.model_name_or_path = model_name_or_path\n",
    "       self.bnb_config=BitsAndBytesConfig(\n",
    "                load_in_4bit=True,\n",
    "                bnb_4bit_compute_dtype=torch.float16,\n",
    "                bnb_4bit_use_double_quant=True,\n",
    "                bnb_4bit_quant_type=\"nf4\",\n",
    "                llm_int8_threshold=6.0,\n",
    "                llm_int8_has_fp16_weight=False,\n",
    "            )\n",
    "   def load(self,for_training=True):  \n",
    "    self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "       self.model_name_or_path, trust_remote_code=True)\n",
    "    if for_training:\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(self.model_name_or_path,\n",
    "                    quantization_config=self.bnb_config, \n",
    "                    trust_remote_code=True)\n",
    "        self.model.config.use_cache = False\n",
    "    else:\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(self.model_name_or_path,\n",
    "                    quantization_config=self.bnb_config,\n",
    "                    trust_remote_code=True)\n",
    "        self.model.config.use_cache=True\n",
    "    \n",
    "    self.model.generation_config = GenerationConfig.from_pretrained(self.model_name_or_path)\n",
    "    self.llm = ChatLLM(self.model,self.tokenizer)\n",
    "    return self.model,self.tokenizer,self.llm\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d5a796f-af85-4b3c-818a-33658c12b907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "register magic %%chat sucessed ...\n"
     ]
    }
   ],
   "source": [
    "model_loader=ModelLoader(model_name_or_path=model_name_or_path)\n",
    "model,tokenizer,llm=model_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "817ef8eb-cac0-472e-a136-d7497b8003bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm.chat(messages=llm.build_messages(query='Align产品之间的转换有哪些规定?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7444e20c-2fbf-4262-9f1d-359832e450e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "智能力引导功能是一种人工智能技术，它可以帮助用户更好地理解和使用人工智能系统。它通过使用自然语言处理、机器学习和深度学习等技术，帮助用户更好地理解人工智能系统的功能和操作方式，并且可以提供有用的建议和指导，以帮助用户更有效地使用人工智能系统。\n"
     ]
    }
   ],
   "source": [
    "%%chat\n",
    "什么是智能力引导功能?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09be19b6-615f-4488-bd27-6dc08a015105",
   "metadata": {},
   "source": [
    "## 一，准备数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ab688d-c5cc-4587-9124-984c07fb94bc",
   "metadata": {},
   "source": [
    "将原始数据用LLM转换成问答对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0df9ed3-d3c0-4b24-9203-6f1b41a99678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \"question\": [ \"什么是智能力引导功能?\", \"智能力引导功能有什么作用?\", \"优化附件和传统附件有什么区别?\" ], \"answer\": \"智能力引导功能是引导并提供正畸牙齿移动所需的生物力学力量的功能。\" }, { \"question\": [ \"优化附件包括哪些?\", \"优化附件如何提供必要的矫治力?\", \"优化附件与传统附件有何不同?\" ], \"answer\": \"优化附件包括用于提供必要的矫治力系统，以实现更多可预测的牙齿移动。每颗牙齿均根据其宽度，长轴和整个牙齿轮廓等特征使用先进技术进行虚拟建模。更精确地定位以提供必要的矫治力，同时消除干扰。与所有智能力引导功能一样，Treat 软件会根据所需的移动自动放置优化附件。\" }, { \"question\": [ \"为什么优化附件的形状与矫治器的附件空泡的形状不同?\", \"为什么我看到附件和矫治器之间存在间隙?\" ], \"answer\": \"优化附件的形状与相应矫治器(上的优化附件位置的)的形状不同。该软件通过两个考虑因素确定矫治器的形状:矫治器的主动面与优化附件的主动面契合并产生牙齿移动所需的矫治力，力施加垂直于主动面的力，而主动面之间没有间隙。非主动面所设计的间隙，避免产生不必要的矫治力。\" }, { \"question\": [ \"使用优化控根附件时，功能面的正确方向是什么?\" ], \"answer\": \"这些优化附件是专为上切牙、上下尖牙和前磨牙在整体移动或直立倾斜时，用来控制根倾斜度而设计的。驱动力来自最靠近中心或阻抗中心的附件，或者来自激活的单个控根附件的 SmartStage。远离阻抗中心的附件(即在两个控根优化附件中离咬合边缘嵴或切缘的附件)或单个优化控附件会提供第二个力来产生反力矩用于倾斜控制。\" }, { \"question\": [ \"在放置了优化控根附件的上颌侧切牙，矫治器在切端位置部分不贴合。这是正常的吗?\" ], \"answer\": \"为了产生预期的矫治力系统，我们在矫治器与牙齿切缘近中或远中的位置预留间隙。该间隙称为矫治器间隙。它位于\n"
     ]
    }
   ],
   "source": [
    "%%chat\n",
    "将以下用···分割的文本中的所有内容转换成多个问题和回答对，将每一个问题的提问用三种不同的方式表达，一个提问匹配一个回答，结果的格式用以下json输出\n",
    "[{“question”:[“问题1\",“问题2”,“问题3\"],“answer”:“问题答案“}]\n",
    "请确保生成的问题列表能涵盖该txt文档中的所有内容，不要有遗漏，保持文本原始的语言，中文的问答依旧用中文，英文的问答依旧用英文\n",
    "···\n",
    "什么是智能力引导功能?\n",
    "智能力引导功能是引导并提供正畸牙齿移动所需的生物力学力量的功能。\n",
    "传统附件和优化附件有什么区别?\n",
    "附件本质上是附着在牙齿表面上的材料，包括先使用粘接剂处理牙面，然后再使用复合树脂粘结。附件与矫治器贴合，为牙齿提供矫治力，提供最佳的正畸牙齿移动。\n",
    "智能力引导功能包括优化附件，它们包括:\n",
    "用于提供必要的矫治力系统，以实现更多可预测的牙齿移动。\n",
    "每颗牙齿均根据其宽度，长轴和整个牙齿轮廓等特征使用先进技术进行虚拟建模。\n",
    "更精确地定位以提供必要的矫治力，同时消除干扰。\n",
    "与所有智能力引导功能一样，Treat 软件会根据所需的移动自动放置优化附件。\n",
    "在查看治疗计划时，医生可以虚拟地放置传统附件。\n",
    "为什么优化附件的形状与矫治器的附件空泡的形状不同? 为什么我看到附件和矫治器之间存在间隙?\n",
    "优化附件的形状与相应矫治器(上的优化附件位置的)的形状不同。该软件通过两个考虑因素确定矫治器的形状:\n",
    "矫治器的主动面与优化附件的主动面契合并产生牙齿移动所需的矫治力，力施加垂直于主动面的力，而主动面之间没有间隙。\n",
    "非主动面所设计的间隙，避免产生不必要的矫治力。\n",
    "使用优化控根附件时，功能面的正确方向是什么?\n",
    "这些优化附件是专为上切牙、上下尖牙和前磨牙在整体移动或直立倾斜时，用来控制根倾斜度而设计的。驱动力来自最靠近中心或阻抗中心的附件，或者来自激活的单个控根附件的 SmartStage。远离阻抗中心的附件(即在两个控根优化附件中离咬合边缘嵴或切缘的附件)或单个优化控附件会提供第二个力来产生反力矩用于倾斜控制。\n",
    "在放置了优化控根附件的上颌侧切牙，矫治器在切端位置部分不贴合。这是正常的吗?\n",
    "为了产生预期的矫治力系统，我们在矫治器与牙齿切缘近中或远中的位置预留间隙。该间隙称为矫治器间隙。它位于与附件相对的牙齿面，以避免不必要的接触及产生不需要的矫治力。矫治器间隙仅出现在放置了优化控根附件的上颌侧切牙。\n",
    "对于前磨牙，为什么我会在某些方案上看到两个优化控根附件而在其他方案上只看到一个?\n",
    "当牙齿有足够的空间时，两个优化控根附件将放置在牙齿的颊面上。当冠高太短时，一个优化控根附件将被放置在颊面上。在最近的更新中，这些附件应与深覆𬌗附件或多颗牙单位附件的一部分区分开来。\n",
    "如果压力点和矫治器空间有助于侧切牙的控根移动，为什么中切牙上没有?\n",
    "中切牙是较大的牙齿，并且通常具有足够的牙齿表面以放置两个控根附件，因此不需要压力点和矫治器间隙。\n",
    "···"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebb00f3b-8304-445f-838c-d53a3c674e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'question': ['什么是智能力引导功能?', '智能力引导功能的作用是什么?', '引入智能力引导功能的目的是什么?'], 'answer': '智能力引导功能是引导并提供正畸牙齿移动所需的生物力学力量的功能。'}, {'question': ['传统附件和优化附件有什么区别?', '请说明传统附件和优化附件的不同之处', '优化附件与传统附件相比有哪些特点?'], 'answer': '附件本质上是附着在牙齿表面上的材料。优化附件包含用于提供必要矫治力系统的先进技术,对每颗牙齿进行虚拟建模,更精确定位以提供必要的矫治力。与传统附件不同,优化附件由Treat软件根据所需移动自动放置。'}, {'question': ['为什么优化附件的形状与矫治器的形状不同?', '优化附件形状与对应矫治器形状不一致的原因是什么?', '优化附件与矫治器形状不同的考虑因素有哪些?'], 'answer': '优化附件的形状与矫治器形状不同。软件通过两个因素确定矫治器形状:主动面之间无间隙以产生牙齿移动所需矫治力;非主动面设计间隙以避免不必要的矫治力。'}, {'question': ['使用优化控根附件时功能面的正确方向是?', '优化控根附件的功能面应该朝向哪个方向?', '优化控根附件的功能面正确方向指的是什么?'], 'answer': '这些优化附件用于控制根倾斜度。驱动力来自最靠近阻抗中心的附件或单个控根附件的SmartStage。远离阻抗中心的附件提供第二个力以产生反力矩用于倾斜控制。'}, {'question': ['放置优化控根附件的上颌侧切牙,矫治器在切端部分不贴合是否正常?', '对于放置了优化控根附件的上颌侧切牙,矫治器在切端有间隙正常吗?', '优化控根附件的上颌侧切牙矫治器切端间隙是预期的现象吗?'], 'answer': '是的。为产生预期的矫治力系统,我们在矫治器与牙齿切缘近中远中留有称为矫治器间隙的间隙,以避免不必要的接触和矫治力。'}, {'question': ['为什么前磨牙在某些方案见到两个优化控根附件,而其他只见一个?', '前磨牙优化控根附件为什么有的方案是两个,有的方案只有一个?', '什么情况下前磨牙会用两个优化控根附件,什么情况下只用一个?'], 'answer': '当牙齿空间足够时会放两个附件在颊面;当冠高太短时会放一个附件在颊面。'}, {'question': ['中切牙没有压力点和矫治器间隙的原因是什么?', '为什么中切牙上没有压力点和矫治器空间?', '中切牙没有压力点和矫治器间隙的考虑因素是什么?'], 'answer': '中切牙是较大的牙齿,并且通常具有足够的牙齿表面以放置两个控根附件,因此不需要压力点和矫治器间隙。'}]\n"
     ]
    }
   ],
   "source": [
    "data=[\n",
    "  {\n",
    "    \"question\": [\n",
    "      \"什么是智能力引导功能?\",\n",
    "      \"智能力引导功能的作用是什么?\",\n",
    "      \"引入智能力引导功能的目的是什么?\"\n",
    "    ],\n",
    "    \"answer\": \"智能力引导功能是引导并提供正畸牙齿移动所需的生物力学力量的功能。\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": [\n",
    "      \"传统附件和优化附件有什么区别?\",\n",
    "      \"请说明传统附件和优化附件的不同之处\",\n",
    "      \"优化附件与传统附件相比有哪些特点?\"\n",
    "    ],\n",
    "    \"answer\": \"附件本质上是附着在牙齿表面上的材料。优化附件包含用于提供必要矫治力系统的先进技术,对每颗牙齿进行虚拟建模,更精确定位以提供必要的矫治力。与传统附件不同,优化附件由Treat软件根据所需移动自动放置。\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": [\n",
    "      \"为什么优化附件的形状与矫治器的形状不同?\",\n",
    "      \"优化附件形状与对应矫治器形状不一致的原因是什么?\",\n",
    "      \"优化附件与矫治器形状不同的考虑因素有哪些?\"\n",
    "    ],\n",
    "    \"answer\": \"优化附件的形状与矫治器形状不同。软件通过两个因素确定矫治器形状:主动面之间无间隙以产生牙齿移动所需矫治力;非主动面设计间隙以避免不必要的矫治力。\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": [\n",
    "      \"使用优化控根附件时功能面的正确方向是?\",\n",
    "      \"优化控根附件的功能面应该朝向哪个方向?\",\n",
    "      \"优化控根附件的功能面正确方向指的是什么?\"\n",
    "    ],\n",
    "    \"answer\": \"这些优化附件用于控制根倾斜度。驱动力来自最靠近阻抗中心的附件或单个控根附件的SmartStage。远离阻抗中心的附件提供第二个力以产生反力矩用于倾斜控制。\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": [\n",
    "      \"放置优化控根附件的上颌侧切牙,矫治器在切端部分不贴合是否正常?\",\n",
    "      \"对于放置了优化控根附件的上颌侧切牙,矫治器在切端有间隙正常吗?\",\n",
    "      \"优化控根附件的上颌侧切牙矫治器切端间隙是预期的现象吗?\"\n",
    "    ],\n",
    "    \"answer\": \"是的。为产生预期的矫治力系统,我们在矫治器与牙齿切缘近中远中留有称为矫治器间隙的间隙,以避免不必要的接触和矫治力。\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": [\n",
    "      \"为什么前磨牙在某些方案见到两个优化控根附件,而其他只见一个?\",\n",
    "      \"前磨牙优化控根附件为什么有的方案是两个,有的方案只有一个?\",\n",
    "      \"什么情况下前磨牙会用两个优化控根附件,什么情况下只用一个?\"\n",
    "    ],\n",
    "    \"answer\": \"当牙齿空间足够时会放两个附件在颊面;当冠高太短时会放一个附件在颊面。\"\n",
    "  }, {\n",
    "    \"question\": [\n",
    "      \"中切牙没有压力点和矫治器间隙的原因是什么?\",\n",
    "      \"为什么中切牙上没有压力点和矫治器空间?\",\n",
    "      \"中切牙没有压力点和矫治器间隙的考虑因素是什么?\"\n",
    "    ],\n",
    "    \"answer\": \"中切牙是较大的牙齿,并且通常具有足够的牙齿表面以放置两个控根附件,因此不需要压力点和矫治器间隙。\"\n",
    "  }]\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2d9290-53a7-4ae3-a1ca-d972512c72cb",
   "metadata": {},
   "source": [
    "### 2，做数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9a76500-01db-4c34-b2ba-6bc1c56233d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader \n",
    "from copy import deepcopy\n",
    "import random\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self,data\n",
    "                ):\n",
    "        self.data = data\n",
    "        self.size = len(data)\n",
    "        self.index_list = list(range(self.size))\n",
    "        \n",
    "        \n",
    "    def get_messages(self):\n",
    "        select = random.choice\n",
    "        messages,history = [],[]\n",
    "        for t in self.data:\n",
    "            history.append((select(t[\"question\"]),t[\"answer\"]))\n",
    "            \n",
    "        for prompt,response in history:\n",
    "            pair = [{\"role\": \"user\", \"content\": prompt},\n",
    "                {\"role\": \"assistant\", \"content\": response}]\n",
    "            messages.extend(pair)\n",
    "        return messages \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "        \n",
    "    def get(self,index):\n",
    "        idx = self.index_list[index]\n",
    "        messages = self.get_messages()\n",
    "        return messages\n",
    "\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        messages = self.get(index)\n",
    "        input_ids, labels = llm.build_inputs_labels(messages,multi_rounds=True) #支持多轮\n",
    "        return {'input_ids':input_ids,'labels':labels}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cc385bf-0103-4720-a4bd-42744aa76f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slider=int(round((len(data)*0.7),0))\n",
    "#ds_train =  MyDataset(data[:slider])\n",
    "#ds_val = MyDataset(data[slider:])\n",
    "ds_train=ds_val= MyDataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18687d89-bc39-42a0-b63c-c8ddb3270452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MyDataset at 0x7f3fbed9bb20>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "892ad81f-b2e6-4e5d-a65c-6ece5195248d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': '智能力引导功能的作用是什么?'},\n",
       " {'role': 'assistant', 'content': '智能力引导功能是引导并提供正畸牙齿移动所需的生物力学力量的功能。'},\n",
       " {'role': 'user', 'content': '请说明传统附件和优化附件的不同之处'},\n",
       " {'role': 'assistant',\n",
       "  'content': '附件本质上是附着在牙齿表面上的材料。优化附件包含用于提供必要矫治力系统的先进技术,对每颗牙齿进行虚拟建模,更精确定位以提供必要的矫治力。与传统附件不同,优化附件由Treat软件根据所需移动自动放置。'},\n",
       " {'role': 'user', 'content': '为什么优化附件的形状与矫治器的形状不同?'},\n",
       " {'role': 'assistant',\n",
       "  'content': '优化附件的形状与矫治器形状不同。软件通过两个因素确定矫治器形状:主动面之间无间隙以产生牙齿移动所需矫治力;非主动面设计间隙以避免不必要的矫治力。'},\n",
       " {'role': 'user', 'content': '优化控根附件的功能面应该朝向哪个方向?'},\n",
       " {'role': 'assistant',\n",
       "  'content': '这些优化附件用于控制根倾斜度。驱动力来自最靠近阻抗中心的附件或单个控根附件的SmartStage。远离阻抗中心的附件提供第二个力以产生反力矩用于倾斜控制。'},\n",
       " {'role': 'user', 'content': '优化控根附件的上颌侧切牙矫治器切端间隙是预期的现象吗?'},\n",
       " {'role': 'assistant',\n",
       "  'content': '是的。为产生预期的矫治力系统,我们在矫治器与牙齿切缘近中远中留有称为矫治器间隙的间隙,以避免不必要的接触和矫治力。'},\n",
       " {'role': 'user', 'content': '前磨牙优化控根附件为什么有的方案是两个,有的方案只有一个?'},\n",
       " {'role': 'assistant', 'content': '当牙齿空间足够时会放两个附件在颊面;当冠高太短时会放一个附件在颊面。'},\n",
       " {'role': 'user', 'content': '为什么中切牙上没有压力点和矫治器空间?'},\n",
       " {'role': 'assistant',\n",
       "  'content': '中切牙是较大的牙齿,并且通常具有足够的牙齿表面以放置两个控根附件,因此不需要压力点和矫治器间隙。'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train.get_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc80b2ee-7d70-41a7-8cf7-2bb5fdfff151",
   "metadata": {},
   "source": [
    "### 3，创建管道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adeee6b-5b37-4290-a45e-6f1201762528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e43aaccc-863e-4794-8cb5-683d5a727ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#如果pad为None，需要处理一下\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.unk_token_id if tokenizer.unk_token_id is not None else tokenizer.eos_token_id\n",
    "    \n",
    "\n",
    "def data_collator(examples: list):\n",
    "    \n",
    "    len_ids = [len(example[\"input_ids\"]) for example in examples]\n",
    "    longest = max(len_ids) #之后按照batch中最长的input_ids进行padding\n",
    "    \n",
    "    input_ids = []\n",
    "    labels_list = []\n",
    "    \n",
    "    for length, example in sorted(zip(len_ids, examples), key=lambda x: -x[0]):\n",
    "        ids = example[\"input_ids\"]\n",
    "        labs = example[\"labels\"]\n",
    "        \n",
    "        ids = ids + [tokenizer.pad_token_id] * (longest - length)\n",
    "        labs = labs + [-100] * (longest - length)\n",
    "        \n",
    "        input_ids.append(torch.LongTensor(ids))\n",
    "        labels_list.append(torch.LongTensor(labs))\n",
    "          \n",
    "    input_ids = torch.stack(input_ids)\n",
    "    labels = torch.stack(labels_list)\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"labels\": labels,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "698aa807-e05a-42a8-b392-747982363075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "dl_train = torch.utils.data.DataLoader(ds_train,batch_size=1,\n",
    "                                       pin_memory=False,shuffle=False,\n",
    "                                       collate_fn = data_collator)\n",
    "\n",
    "dl_val = torch.utils.data.DataLoader(ds_val,batch_size=1,\n",
    "                                    pin_memory=False,shuffle=False,\n",
    "                                     collate_fn = data_collator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db52d785-10de-4465-8fc2-9eaccaf3387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dl_train:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35002105-b8e8-4d48-a8a2-cbd4ceaa53ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#试跑一个batch\n",
    "#out = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c721189c-6443-4e10-b923-327a0beba2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#out.loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cac7d4a-a37b-4c30-8a7d-be552d8e67ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(dl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fd7e26-985a-4392-ba0d-acb254064677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5aa1deea-3fc4-4051-80e9-89de248d3107",
   "metadata": {},
   "source": [
    "## 二，定义模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644837f5-bbc4-4f4f-a5f0-1f763e36f373",
   "metadata": {},
   "source": [
    "下面我们将使用QLoRA(实际上用的是量化的AdaLoRA）算法来微调Baichuan-13b模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7dbbece-2e50-4166-9e43-ea35d04af856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_config, get_peft_model, TaskType\n",
    "model.supports_gradient_checkpointing = True  #\n",
    "model.gradient_checkpointing_enable()\n",
    "model.enable_input_require_grads()\n",
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc66d6a4-77ff-490c-a3c0-913a9316eb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bitsandbytes as bnb \n",
    "def find_all_linear_names(model):\n",
    "    \"\"\"\n",
    "    找出所有全连接层，为所有全连接添加adapter\n",
    "    \"\"\"\n",
    "    cls = bnb.nn.Linear4bit\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "\n",
    "    if 'lm_head' in lora_module_names:  # needed for 16-bit\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "587a53eb-ba75-40a6-83e6-1ad2684738f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training \n",
    "model = prepare_model_for_kbit_training(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffbd01ad-2667-4c38-8ce7-62ce293e759e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c_attn', 'w2', 'c_proj', 'w1']\n"
     ]
    }
   ],
   "source": [
    "lora_modules = find_all_linear_names(model)\n",
    "print(lora_modules) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5b68e33-3c18-4044-9554-c453b17d4fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 41,843,040 || all params: 14,209,134,120 || trainable%: 0.2944798722189836\n"
     ]
    }
   ],
   "source": [
    "from peft import AdaLoraConfig\n",
    "peft_config = AdaLoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, inference_mode=False,\n",
    "    r=16,\n",
    "    lora_alpha=16, lora_dropout=0.08,\n",
    "    target_modules= lora_modules\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "\n",
    "peft_model.is_parallelizable = True\n",
    "peft_model.model_parallel = True\n",
    "peft_model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c396dc8-f574-4c7b-80dc-7e3a168e88ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ad2444d-2c9c-4048-958c-ae48d9590dfd",
   "metadata": {},
   "source": [
    "## 三，训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9317cd85-b886-4153-af53-42c83921525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchkeras import KerasModel \n",
    "from accelerate import Accelerator \n",
    "\n",
    "class StepRunner:\n",
    "    def __init__(self, net, loss_fn, accelerator=None, stage = \"train\", metrics_dict = None, \n",
    "                 optimizer = None, lr_scheduler = None\n",
    "                 ):\n",
    "        self.net,self.loss_fn,self.metrics_dict,self.stage = net,loss_fn,metrics_dict,stage\n",
    "        self.optimizer,self.lr_scheduler = optimizer,lr_scheduler\n",
    "        self.accelerator = accelerator if accelerator is not None else Accelerator() \n",
    "        torch.cuda.empty_cache()\n",
    "        if self.stage=='train':\n",
    "            self.net.train() \n",
    "        else:\n",
    "            self.net.eval()\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        \n",
    "        #loss\n",
    "        with self.accelerator.autocast():\n",
    "            loss = self.net.forward(**batch)[0]\n",
    "            \n",
    "\n",
    "        #backward()\n",
    "        if self.optimizer is not None and self.stage==\"train\":\n",
    "            torch.cuda.empty_cache()\n",
    "            self.accelerator.backward(loss)\n",
    "            torch.cuda.empty_cache()\n",
    "            if self.accelerator.sync_gradients:\n",
    "                self.accelerator.clip_grad_norm_(self.net.parameters(), 1.0)\n",
    "            self.optimizer.step()\n",
    "            if self.lr_scheduler is not None:\n",
    "                self.lr_scheduler.step()\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "        all_loss = self.accelerator.gather(loss).sum()\n",
    "        \n",
    "        #losses (or plain metrics that can be averaged)\n",
    "        step_losses = {self.stage+\"_loss\":all_loss.item()}\n",
    "        \n",
    "        #metrics (stateful metrics)\n",
    "        step_metrics = {}\n",
    "        \n",
    "        if self.stage==\"train\":\n",
    "            if self.optimizer is not None:\n",
    "                step_metrics['lr'] = self.optimizer.state_dict()['param_groups'][0]['lr']\n",
    "            else:\n",
    "                step_metrics['lr'] = 0.0\n",
    "        return step_losses,step_metrics\n",
    "    \n",
    "KerasModel.StepRunner = StepRunner \n",
    "\n",
    "#仅仅保存QLora可训练参数\n",
    "def save_ckpt(self, ckpt_path='checkpoint', accelerator = None):\n",
    "    unwrap_net = accelerator.unwrap_model(self.net)\n",
    "    unwrap_net.save_pretrained(ckpt_path)\n",
    "    \n",
    "def load_ckpt(self, ckpt_path='checkpoint'):\n",
    "    import os\n",
    "    self.net.load_state_dict(\n",
    "        torch.load(os.path.join(ckpt_path,'adapter_model.bin')),strict =False)\n",
    "    self.from_scratch = False\n",
    "    \n",
    "KerasModel.save_ckpt = save_ckpt \n",
    "KerasModel.load_ckpt = load_ckpt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "353a96d4-0fef-419a-a345-f5a5342ab8cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Accelerator.__init__() got an unexpected keyword argument 'num_processes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m bnb\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39madamw\u001b[38;5;241m.\u001b[39mAdamW(peft_model\u001b[38;5;241m.\u001b[39mparameters(),\n\u001b[1;32m      2\u001b[0m                                   lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6e-03\u001b[39m,is_paged\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m#'paged_adamw'\u001b[39;00m\n\u001b[1;32m      3\u001b[0m keras_model \u001b[38;5;241m=\u001b[39m KerasModel(peft_model,loss_fn \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m----> 4\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39moptimizer,accelerator\u001b[38;5;241m=\u001b[39m\u001b[43mAccelerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmixed_precision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mno\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnum_processes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m) \n\u001b[1;32m      7\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m llm_finetune_checkpoint_workspace\n",
      "\u001b[0;31mTypeError\u001b[0m: Accelerator.__init__() got an unexpected keyword argument 'num_processes'"
     ]
    }
   ],
   "source": [
    "optimizer = bnb.optim.adamw.AdamW(peft_model.parameters(),\n",
    "                                  lr=6e-03,is_paged=True)  #'paged_adamw'\n",
    "keras_model = KerasModel(peft_model,loss_fn =None,\n",
    "        optimizer=optimizer,accelerator=Accelerator(mixed_precision=\"no\",cpu=False,\n",
    "            gradient_accumulation_steps=1,num_processes=4)) \n",
    "\n",
    "ckpt_path = llm_finetune_checkpoint_workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a409456-ad9d-4b28-b6c0-5f22e0212abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model.from_scratch=False\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131ba617-d6e6-4bf7-9259-daaa113ada8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras_model.load_ckpt(ckpt_path) #支持加载微调后的权重继续训练(断点续训)\n",
    "keras_model.fit(train_data = dl_train,\n",
    "                val_data = dl_val, \n",
    "                epochs=100,patience=15,\n",
    "                monitor='val_loss',mode='min',\n",
    "                ckpt_path = ckpt_path\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2109a2d-c2d9-472f-bf44-42686177b32e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4988c80-b699-45e5-aceb-84046d9a592d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49763c6a-6ee5-448c-b873-48825a6fba67",
   "metadata": {},
   "source": [
    "## 四，保存模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f98c4e5-dbb0-456e-bc4b-1c8dfccbd499",
   "metadata": {},
   "source": [
    "为减少GPU压力，此处可重启kernel释放显存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee686c58-42e2-463a-a429-3fe16dee5a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "142a917e-9db0-4d5a-8352-cb250561f47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: please make sure that you are using the latest codes and checkpoints, especially if you used Qwen-7B before 09.25.2023.请使用最新模型和代码，尤其如果你在9月25日前已经开始使用Qwen-7B，千万注意不要使用错误代码和模型。\n",
      "The model is automatically converting to fp16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
      "Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eabe41e8c664cc4905fabdddfebf6bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM,AutoConfig, AutoModel, BitsAndBytesConfig\n",
    "from transformers.generation.utils import GenerationConfig\n",
    "import torch.nn as nn\n",
    "#使用QLoRA引入的 NF4量化数据类型以节约显存\n",
    "\n",
    "ckpt_path = ckpt_path\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "   model_name_or_path, trust_remote_code=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\n",
    "                trust_remote_code=True) \n",
    "\n",
    "model.generation_config = GenerationConfig.from_pretrained(model_name_or_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a8b409f-f100-48c5-9794-62cb5bdf19d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "#可能需要5分钟左右\n",
    "peft_model = PeftModel.from_pretrained(model, ckpt_path)\n",
    "model_new = peft_model.merge_and_unload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c060b4a-7731-4ec7-8699-9f47088f4a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.generation.utils import GenerationConfig\n",
    "model_new.generation_config = GenerationConfig.from_pretrained(model_name_or_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce165cd8-987d-47be-95ac-83cf7ef479b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = llm_finetune_savepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9214d354-811b-4e47-96ac-682ed5e68ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(save_path)\n",
    "model_new.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33e8a14c-dbfc-4c7c-b22c-ec2d6dc045c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "a = os.system(\"cp \"+model_name_or_path+\"/*.py \"+save_path)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e242ae9b-f79f-44eb-8c39-57d7423e8cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json\n",
      "configuration_qwen.py\n",
      "cpp_kernels.py\n",
      "generation_config.json\n",
      "modeling_qwen.py\n",
      "pytorch_model-00001-of-00002.bin\n",
      "pytorch_model-00002-of-00002.bin\n",
      "pytorch_model.bin.index.json\n",
      "qwen_generation_utils.py\n",
      "qwen.tiktoken\n",
      "special_tokens_map.json\n",
      "tokenization_qwen.py\n",
      "tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "a = os.system(\"ls \"+save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcfb0f3-bfc3-43cd-944e-d5b0fe785a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c92003-2d55-416a-b9f1-f58b5fb29261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81582c3e-28d3-4847-a84c-dc1b53aa0839",
   "metadata": {},
   "source": [
    "## 五，使用模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c57c2f-0e1a-4e77-b4e4-fefa210b1bb1",
   "metadata": {},
   "source": [
    "为减少GPU压力，此处可再次重启kernel释放显存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89fc27d5-651e-437c-ab1c-adacb487a614",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd4ba13a-3525-4818-bc4c-f5b7d4621895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "register magic %%chat sucessed ...\n",
      "Using bos_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using sep_token, but it is not set yet.\n",
      "Using pad_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(QWenLMHeadModel(\n",
       "   (transformer): QWenModel(\n",
       "     (wte): Embedding(151936, 4096)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "     (rotary_emb): RotaryEmbedding()\n",
       "     (h): ModuleList(\n",
       "       (0-31): 32 x QWenBlock(\n",
       "         (ln_1): RMSNorm()\n",
       "         (attn): QWenAttention(\n",
       "           (c_attn): Linear4bit(in_features=4096, out_features=12288, bias=True)\n",
       "           (c_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "           (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "         (ln_2): RMSNorm()\n",
       "         (mlp): QWenMLP(\n",
       "           (w1): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "           (w2): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "           (c_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (ln_f): RMSNorm()\n",
       "   )\n",
       "   (lm_head): Linear(in_features=4096, out_features=151936, bias=False)\n",
       " ),\n",
       " QWenTokenizer(name_or_path='/mnt/llm-data/finetuned/qwen/Qwen-7B-Chat', vocab_size=151851, model_max_length=8192, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       " \t\n",
       " },\n",
       " <torchkeras.chat.chatllm.ChatLLM at 0x7faed2acd660>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM,AutoConfig, AutoModel, BitsAndBytesConfig\n",
    "from transformers.generation.utils import GenerationConfig\n",
    "import torch.nn as nn\n",
    "model_loader=ModelLoader(model_name_or_path=llm_finetune_savepath)\n",
    "model_loader.load(for_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5333f116-5bc2-46d9-ba39-54d9e14b9ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e63d6988-4cfd-46ba-8a5d-f11e5d183483",
   "metadata": {},
   "source": [
    "我们测试一下微调后的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c7802d-b07f-44d1-ba2b-0c7ede473b77",
   "metadata": {},
   "source": [
    "先用训练集中的一条数据中的三种不同的问法提问，原始训练数据如下：\n",
    "```json\n",
    "{\n",
    "    \"question\": [\n",
    "      \"什么是智能力引导功能?\",\n",
    "      \"智能力引导功能的作用是什么?\",\n",
    "      \"引入智能力引导功能的目的是什么?\"\n",
    "    ],\n",
    "    \"answer\": \"智能力引导功能是引导并提供正畸牙齿移动所需的生物力学力量的功能。\"\n",
    "  }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e6e40b3-4cf8-4e7e-8f21-9b3487adc327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "智能力引导功能是引导并提供正畸牙齿移动所需的生物力学力量的功能。\n"
     ]
    }
   ],
   "source": [
    "%%chat\n",
    "什么是智能力引导功能?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f7464f4-e642-49fe-8ae2-1de29ef2fe3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "智能力引导功能是引导并提供正畸牙齿移动所需的生物力学力量的功能。\n"
     ]
    }
   ],
   "source": [
    "%%chat\n",
    "智能力引导功能的作用是什么?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a37da7c-4f03-45ae-9937-5ca27510a701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "智能力引导功能是隐形式力,用于更精细地控制牙齿移动,因此能提供超凡的矫治力控制。\n"
     ]
    }
   ],
   "source": [
    "%%chat\n",
    "引入智能力引导功能的目的是什么?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8282b4ce-d40b-4936-9f0c-c5707c814bff",
   "metadata": {},
   "source": [
    "同时问两个问题\n",
    "\n",
    "```json\n",
    "原始训练数据\n",
    "{\n",
    "    \"question\": [\n",
    "      \"为什么优化附件的形状与矫治器的形状不同?\",\n",
    "      \"优化附件形状与对应矫治器形状不一致的原因是什么?\",\n",
    "      \"优化附件与矫治器形状不同的考虑因素有哪些?\"\n",
    "    ],\n",
    "    \"answer\": \"优化附件的形状与矫治器形状不同。软件通过两个因素确定矫治器形状:主动面之间无间隙以产生牙齿移动所需矫治力;非主动面设计间隙以避免不必要的矫治力。\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": [\n",
    "      \"为什么前磨牙在某些方案见到两个优化控根附件,而其他只见一个?\",\n",
    "      \"前磨牙优化控根附件为什么有的方案是两个,有的方案只有一个?\",\n",
    "      \"什么情况下前磨牙会用两个优化控根附件,什么情况下只用一个?\"\n",
    "    ],\n",
    "    \"answer\": \"当牙齿空间足够时会放两个附件在颊面;当冠高太短时会放一个附件在颊面。\"\n",
    "  }\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9118f319-09fd-4888-9ae1-9dc34fe9dee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 优化附件形状与矫治器形状不同,因为前者需要考虑根倾斜、颊面倾斜以及可能的牙齿冠高。2. 前磨牙牙齿移动速度比后牙快,因此在某些正畸方案中需要使用两个优化附件以增加控制力。\n"
     ]
    }
   ],
   "source": [
    "%%chat\n",
    "请回答两个问题，1.为什么优化附件的形状与矫治器的形状不同? 2.为什么前磨牙在某些方案见到两个优化控根附件,而其他只见一个?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be726a3a-f6ee-49dd-9f2e-1d74503caf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "您刚才问了两个问题。第一个问题是：“为什么优化附件的形状与矫治器的形状不同?” 第二个问题是：“为什么前磨牙在某些方案见到两个优化控根附件,而其他只见一个?”。\n"
     ]
    }
   ],
   "source": [
    "%%chat\n",
    "刚才问了什么问题？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66338900-f019-4a92-bd68-640fe5836d18",
   "metadata": {},
   "source": [
    "```json\n",
    "{\n",
    "    \"question\": [\n",
    "      \"放置优化控根附件的上颌侧切牙,矫治器在切端部分不贴合是否正常?\",\n",
    "      \"对于放置了优化控根附件的上颌侧切牙,矫治器在切端有间隙正常吗?\",\n",
    "      \"优化控根附件的上颌侧切牙矫治器切端间隙是预期的现象吗?\"\n",
    "    ],\n",
    "    \"answer\": \"是的。为产生预期的矫治力系统,我们在矫治器与牙齿切缘近中远中留有称为矫治器间隙的间隙,以避免不必要的接触和矫治力。\"\n",
    "  }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "49dea769-8a50-432f-ba43-5e71fe3b557b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是的。为产生预期的矫治力系统,我们在矫治器与牙齿切缘近中远中留有称为矫治器间隙的间隙,以避免不必要的接触和矫治力。\n"
     ]
    }
   ],
   "source": [
    "%%chat\n",
    "对于放置了优化控根附件的上颌侧切牙,矫治器在切端有间隙正常吗?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df16f1ab-44cd-4a87-aec1-5f58d220817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%chat\n",
    "刚才问了什么问题？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06d36525-3ffe-4894-bbfb-f7340a06c79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是的，您刚才问了几个问题。我是一个大型语言模型，可以回答各种问题。如果您有任何问题，请随时告诉我。我会尽力提供帮助。\n"
     ]
    }
   ],
   "source": [
    "%%chat\n",
    "刚才问了几个问题？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ee0337-dfe4-4a16-a374-be6bd35a1c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995220d6-3cb5-4572-8dff-c2f4b13049d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4acbcbd-7aa3-47a4-84de-42c0068b9730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9876dd1-3a5f-425e-b2bc-5a19a9b27ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a58d02-ecd4-4250-964a-e7302c74646b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca93063-ce3a-4828-9ddc-0dfec424b84f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025e01ee-cedc-4e1e-be13-e0ea42c8a7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
